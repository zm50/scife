import streamlit as st
from langchain.agents import ConversationalChatAgent, AgentExecutor
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_core.memory import ConversationBufferMemory
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.tools import Tool
from langchain_community.vectorstores import FAISS
from langchain_community.callbacks import StreamlitCallbackHandler
from langchain_community.chat_message_histories import StreamlitChatMessageHistory
from langchain_community.chat_models import ChatTongyi
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.runnables import RunnableConfig

from utils import is_token_expired, extract_files

st.set_page_config(page_title="è®ºæ–‡é—®ç­”", page_icon="ğŸ¤–")
st.title('ğŸ¤–è®ºæ–‡é—®ç­”')






def show_chat(msgs):
    avatars = {"human": "user", "ai": "assistant"}
    for idx, msg in enumerate(msgs.messages):
        with st.chat_message(avatars[msg.type]):
            # Render intermediate steps if any were saved
            for step in st.session_state.steps.get(str(idx), []):
                if step[0].tool == "_Exception":
                    continue
                with st.status(f"**{step[0].tool}**: {step[0].tool_input}", state="complete"):
                    st.write(step[0].log)
                    st.write(step[1])
            st.write(msg.content)

def reset_chat_history(msgs):
    """é‡ç½®èŠå¤©å†å²"""
    msgs.clear()
    if 'steps' in st.session_state:
        st.session_state.steps = {}
    # æ¸…é™¤æ–‡æ¡£ç›¸å…³çš„ç¼“å­˜
    if 'current_doc' in st.session_state:
        del st.session_state.current_doc
    if 'vectorstore' in st.session_state:
        del st.session_state.vectorstore

def main():
    msgs = StreamlitChatMessageHistory()
    memory = ConversationBufferMemory(
        chat_memory=msgs, return_messages=True, memory_key="chat_history", output_key="output"
    )
    
    # åˆå§‹åŒ– selected_doc_index
    if 'selected_doc_index' not in st.session_state:
        st.session_state.selected_doc_index = 0
    
    # é€šè¿‡ä¸‹æ‹‰æ¡†é€‰æ‹©æ–‡æ¡£
    document_names = [file['file_name'] for file in st.session_state['files']]
    selected_doc_name = st.selectbox(
        "é€‰æ‹©æ–‡æ¡£", 
        document_names,
        index=st.session_state.selected_doc_index,  # ä½¿ç”¨ä¿å­˜çš„ç´¢å¼•
        on_change=lambda: reset_chat_history(msgs),
        key='doc_selector'  # æ·»åŠ å”¯ä¸€çš„key
    )
    
    # æ›´æ–°é€‰ä¸­çš„æ–‡æ¡£ç´¢å¼•
    st.session_state.selected_doc_index = document_names.index(selected_doc_name)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŠ è½½æ–‡æ¡£
    current_doc = st.session_state.get('current_doc', {})
    if current_doc.get('name') != selected_doc_name:
        # åªåœ¨æ–‡æ¡£æ”¹å˜æ—¶é‡æ–°åŠ è½½
        document_result = extract_files(st.session_state['files'][document_names.index(selected_doc_name)]['file_path'])
        
        if document_result['result'] == 1:
            # ç¼“å­˜æ–‡æ¡£å†…å®¹å’Œåç§°
            st.session_state.current_doc = {
                'name': selected_doc_name,
                'content': document_result['text']
            }
            
            # åˆ›å»ºå‘é‡å­˜å‚¨
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=500,
                chunk_overlap=50,
                separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?"]
            )
            chunks = text_splitter.split_text(document_result['text'])
            
            embeddings = DashScopeEmbeddings(model='text-embedding-v1')
            st.session_state.vectorstore = FAISS.from_texts(chunks, embeddings)
        else:
            st.error("æ–‡æ¡£åŠ è½½å¤±è´¥ï¼š" + str(document_result['text']))
            return
    
    # ä½¿ç”¨ç¼“å­˜çš„æ–‡æ¡£å†…å®¹å’Œå‘é‡å­˜å‚¨
    if 'current_doc' in st.session_state and 'vectorstore' in st.session_state:
        document_content = st.session_state.current_doc['content']
        retriever = st.session_state.vectorstore.as_retriever(search_kwargs={"k": 5})

        def search_doc(query: str) -> str:
            """ä½¿ç”¨è¯¥å·¥å…·åœ¨æ–‡æ¡£ä¸­æœç´¢ç›¸å…³å†…å®¹"""
            docs = retriever.get_relevant_documents(query)
            return "\n".join([doc.page_content for doc in docs])

        tools = [
            Tool(
                name="SearchDocument",
                func=search_doc,
                description="å½“éœ€è¦æŸ¥æ‰¾æ–‡æ¡£ä¸­çš„å…·ä½“å†…å®¹æ—¶ä½¿ç”¨æ­¤å·¥å…·,è¾“å…¥å…·ä½“çš„é—®é¢˜æˆ–å…³é”®è¯"
            ),
            DuckDuckGoSearchRun(name="Search"),
        ]

        if len(msgs.messages) <= 1:
            msgs.clear()
            # è½¬ä¹‰æ–‡æ¡£å†…å®¹ä¸­çš„èŠ±æ‹¬å·
            safe_content = document_content.replace("{", "{{").replace("}", "}}")
            
            system_message = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®ºæ–‡é—®ç­”åŠ©æ‰‹ã€‚

æˆ‘ä¼šç»™ä½ ä¸€ç¯‡è®ºæ–‡å†…å®¹ï¼š

{}

è¯·åŸºäºä»¥ä¸Šè®ºæ–‡å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å›ç­”æ—¶è¯·æ³¨æ„:
1. ä¼˜å…ˆä½¿ç”¨è®ºæ–‡ä¸­çš„å†…å®¹å›ç­”
2. ä½¿ç”¨ SearchDocument å·¥å…·æŸ¥æ‰¾å…·ä½“ç»†èŠ‚
3. ä»…å½“è®ºæ–‡å†…å®¹æ— æ³•å›ç­”æ—¶,æ‰ä½¿ç”¨ Search å·¥å…·è”ç½‘æŸ¥è¯¢
4. å›ç­”è¦ç®€æ´æ¸…æ™°,å¹¶æ ‡æ³¨ä¿¡æ¯æ¥æº

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡º
2. é‡è¦å†…å®¹ä½¿ç”¨**åŠ ç²—**æ ‡è®°
3. ä½¿ç”¨é€‚å½“çš„æ ‡é¢˜å±‚çº§(###, ####)ç»„ç»‡å†…å®¹
4. æ•°å­¦å…¬å¼ä½¿ç”¨ LaTeX æ ¼å¼ï¼š
   - è¡Œå†…å…¬å¼ä½¿ç”¨å•ä¸ª$åŒ…è£¹
   - ç‹¬ç«‹å…¬å¼å—ä½¿ç”¨$$åŒ…è£¹
5. å¦‚æœ‰å¿…è¦ä½¿ç”¨åˆ—è¡¨æˆ–è¡¨æ ¼å¢å¼ºå¯è¯»æ€§
6. å¼•ç”¨åŸæ–‡æ—¶ä½¿ç”¨>å¼•ç”¨æ ¼å¼
7. å…³é”®æ¦‚å¿µæˆ–æœ¯è¯­ä½¿ç”¨`ä»£ç å—`æ ‡è®°""".format(safe_content)

            msgs.add_ai_message(f"å·²åŠ è½½æ–‡æ¡£ {selected_doc_name},æˆ‘å·²ç»é˜…è¯»äº†å…¨æ–‡,è¯·é—®æœ‰ä»€ä¹ˆé—®é¢˜?")
            st.session_state.steps = {}
        else:
            system_message = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è®ºæ–‡é—®ç­”åŠ©æ‰‹ã€‚å›ç­”é—®é¢˜æ—¶è¯·éµå¾ªä»¥ä¸‹ç­–ç•¥:
1. ä¼˜å…ˆä½¿ç”¨ SearchDocument å·¥å…·åœ¨æ–‡æ¡£ä¸­æœç´¢ç›¸å…³å†…å®¹
2. å¦‚æœæœç´¢ç»“æœä¸å®Œæ•´,å¯ä»¥è¿½åŠ æœç´¢å…¶ä»–ç›¸å…³å†…å®¹
3. ä»…å½“æ–‡æ¡£å†…æœç´¢æ— æ³•è§£ç­”æ—¶,æ‰ä½¿ç”¨ Search å·¥å…·è”ç½‘æŸ¥è¯¢
4. å›ç­”è¦ç®€æ´æ¸…æ™°,å¹¶æ ‡æ³¨ä¿¡æ¯æ¥æº

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
1. ä½¿ç”¨ Markdown æ ¼å¼è¾“å‡º
2. é‡è¦å†…å®¹ä½¿ç”¨**åŠ ç²—**æ ‡è®°
3. ä½¿ç”¨é€‚å½“çš„æ ‡é¢˜å±‚çº§(###, ####)ç»„ç»‡å†…å®¹
4. æ•°å­¦å…¬å¼ä½¿ç”¨ LaTeX æ ¼å¼ï¼š
   - è¡Œå†…å…¬å¼ä½¿ç”¨å•ä¸ª$åŒ…è£¹
   - ç‹¬ç«‹å…¬å¼å—ä½¿ç”¨$$åŒ…è£¹
5. å¦‚æœ‰å¿…è¦ä½¿ç”¨åˆ—è¡¨æˆ–è¡¨æ ¼å¢å¼ºå¯è¯»æ€§
6. å¼•ç”¨åŸæ–‡æ—¶ä½¿ç”¨>å¼•ç”¨æ ¼å¼
7. å…³é”®æ¦‚å¿µæˆ–æœ¯è¯­ä½¿ç”¨`ä»£ç å—`æ ‡è®°"""

        show_chat(msgs)
        if prompt := st.chat_input():
            st.chat_message("user").write(prompt)
            llm = ChatTongyi(model_name="qwen-max", streaming=True)
            chat_agent = ConversationalChatAgent.from_llm_and_tools(
                llm=llm,
                tools=tools,
                system_message=system_message,
                input_variables=["input", "chat_history", "agent_scratchpad"]  # æ˜ç¡®æŒ‡å®šè¾“å…¥å˜é‡
            )

            executor = AgentExecutor.from_agent_and_tools(
                agent=chat_agent,
                memory=memory,
                return_intermediate_steps=True,
                handle_parsing_errors=True,
                verbose=True,
                tools=tools
            )
            
            with st.chat_message("assistant"):
                st_cb = StreamlitCallbackHandler(st.container(), expand_new_thoughts=False)
                cfg = RunnableConfig()
                cfg["callbacks"] = [st_cb]
                response = executor.invoke(
                    {
                        "input": prompt,
                        "chat_history": memory.chat_memory.messages,
                    }, 
                    cfg
                )
                st.markdown(response["output"])
                st.session_state.steps[str(len(msgs.messages) - 1)] = response["intermediate_steps"]


# init
if 'files' not in st.session_state:
    st.session_state.files = []

if 'current_doc' not in st.session_state:
    st.session_state.current_doc = {}

if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None


if (not st.session_state['token']) or is_token_expired(st.session_state['token']):
    st.error('è¿˜æ²¡ç™»å½•å“¦')
elif not st.session_state.files:
    st.write('### è¿˜æ²¡ä¸Šä¼ æ–‡æ¡£å“¦')
else:
    main()
